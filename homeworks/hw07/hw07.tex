\documentclass[12pt]{article}

\include{preamble}

\newtoggle{professormode}
\toggletrue{professormode} %STUDENTS: DELETE or COMMENT this line



\title{MATH 341 / 650.3 Spring 2020 Homework \#7}

\author{Professor Adam Kapelner} %STUDENTS: write your name here

\iftoggle{professormode}{
\date{Due by email, Friday 11:59PM, May 8, 2020 \\ \vspace{0.5cm} \small (this document last updated \today ~at \currenttime)}
}

\renewcommand{\abstractname}{Instructions and Philosophy}

\begin{document}
\maketitle

\iftoggle{professormode}{
\begin{abstract}
The path to success in this class is to do many problems. Unlike other courses, exclusively doing reading(s) will not help. Coming to lecture is akin to watching workout videos; thinking about and solving problems on your own is the actual ``working out.''  Feel free to \qu{work out} with others; \textbf{I want you to work on this in groups.}

Reading is still \textit{required}. For this homework set, read about the normal-inverse -gamma / normal-inverse-gamma conjugate model and its marginal posterior distributions and its posterior predictive distribution. Review the general Students $T_\nu$ distribution. Read chapter 16 in the McGrayne book - a very long and important chapter.

The problems below are color coded: \ingreen{green} problems are considered \textit{easy} and marked \qu{[easy]}; \inorange{yellow} problems are considered \textit{intermediate} and marked \qu{[harder]}, \inred{red} problems are considered \textit{difficult} and marked \qu{[difficult]} and \inpurple{purple} problems are extra credit. The \textit{easy} problems are intended to be ``giveaways'' if you went to class. Do as much as you can of the others; I expect you to attempt the \textit{difficult} problems. 

Problems marked \qu{[MA]} are for the masters students only (those enrolled in the 650.3 course). For those in 341, doing these questions will count as extra credit.

This homework is worth 100 points but the point distribution will not be determined until after the due date. See syllabus for the policy on late homework.

Up to 10 points are given as a bonus if the homework is typed using \LaTeX. Links to instaling \LaTeX~and program for compiling \LaTeX~is found on the syllabus. You are encouraged to use \url{overleaf.com}. If you are handing in homework this way, read the comments in the code; there are two lines to comment out and you should replace my name with yours and write your section. The easiest way to use overleaf is to copy the raw text from hwxx.tex and preamble.tex into two new overleaf tex files with the same name. If you are asked to make drawings, you can take a picture of your handwritten drawing and insert them as figures or leave space using the \qu{$\backslash$vspace} command and draw them in after printing or attach them stapled.

The document is available with spaces for you to write your answers. If not using \LaTeX, print this document and write in your answers. I do not accept homeworks which are \textit{not} on this printout. Keep this first page printed for your records.

\end{abstract}

\thispagestyle{empty}
\vspace{1cm}
NAME: \line(1,0){380}
\clearpage
}



\problem{These are questions about McGrayne's book, chapter 16.}

\begin{enumerate}
\easysubproblem{What was the main problem facing Bayesian Statistics in the early 1980's?}\spc{4}

\intermediatesubproblem{What is the \qu{curse of dimensionality?}}\spc{4}

\easysubproblem{How did Bayesian Statistics help sociologists?}\spc{4}

\easysubproblem{How did Gibbs sampling come to be?}\spc{3}

\easysubproblem{Were the Geman brothers the first to discover the Gibbs sampler?}\spc{4}

\easysubproblem{Who officially discovered the expectation-maximization (EM) algorithm? And who \textit{really} discovered it?}\spc{4}

\intermediatesubproblem{How did Bayesians \qu{break} the curse of dimensionality?}\spc{4}

\intermediatesubproblem{Consider the integrals we use in class to find expectations or to approximate PDF's / PMF's --- how can they be replaced?}\spc{4}

\easysubproblem{What did physicists call \qu{Markov Chain Monte Carlo} (MCMC)? (p222)}\spc{1}

\easysubproblem{Why is sampling called \qu{Monte Carlo} and who named it that?}\spc{4}

\easysubproblem{The Metropolis-Hastings (MH) Algorithm is world famous and used in myriad applications. Why didn't Hastings get any credit?}\spc{4}

\easysubproblem{The combination of Bayesian Statistics + MCMC has been called ... (p224)}\spc{1}


\extracreditsubproblem{p225 talks about Thomas Kuhn's ideas of \qu{paradigm shifts.} What is a \qu{paradigm shift} and does Bayesian Statistics + MCMC qualify?}\spc{8}

\easysubproblem{How did the \href{http://www.mrc-bsu.cam.ac.uk/software/bugs/}{BUGS} software change the world?}\spc{4}

\easysubproblem{Lindley said that Bayesian Statistics would win out over Frequentist Statistics because it was more logical. What in reality was the reason for the eventual victory of Bayes?}\spc{4}

\extracreditsubproblem{One of my PhD advisors, \href{https://statistics.wharton.upenn.edu/profile/563/}{Ed George} at Wharton told me that \qu{Bayesian Statistics is really `knowledge engineering.'} Is this true? Explain.}\spc{3}

\extracreditsubproblem{Take a look at the software \href{http://mc-stan.org/}{Stan}. What kind of potential does it have to change the world? Note: I had an opportunity to work on Stan as a postdoc (right after I finished his PhD) but chose to come to QC instead.}\spc{10}

\end{enumerate}




\input{R_equations_table}



\problem{Now we will move to the Bayesian normal-normal model for estimating both the mean and variance and demonstrate similarities with the classical results.}

\begin{enumerate}

\intermediatesubproblem{If $\Xoneton~|~\theta, \sigsq \iid \normnot{\theta}{\sigsq}$ and $X$ represents all $\Xoneton$, Find the kernel of $\cprob{\theta,~\sigsq}{X}$ if $\prob{\theta,~\sigsq} \propto \oneover{\sigsq}$. Use the substitution that we made in class:

\beqn
\sum_{i=1}^n (x_i - \theta)^2 = (n-1)s^2 + n(\xbar - \theta)^2
\eeqn

where $s^2 := \oneover{n-1} \sum_{i=1}^n (x_i -\xbar)^2$. We do this here because this substitution is important for what comes next.}\spc{8}


\intermediatesubproblem{Using Bayes Rule, break up $\cprob{\theta,~\sigsq}{X}$ into two pieces. How are those two pieces distributed?}\spc{6}

\intermediatesubproblem{Using your answer from (b), explain in English how you can create samples from the distribution $\cprob{\theta,~\sigsq}{X}$ that look like $\braces{\bracks{\theta_1, \sigsq_1}, \bracks{\theta_2, \sigsq_2}, \ldots, \bracks{\theta_S, \sigsq_S}}$.}\spc{8}

\hardsubproblem{Using these samples, how would you estimate $\cexpe{\theta}{X}$ and $\cexpe{\sigsq}{X}$? Why is $\cexpe{\theta}{X}$ of paramount importance?}\spc{5}


\hardsubproblem{Using these samples, how would you estimate a 95\% CR for $\theta$?}\spc{5}

\hardsubproblem{Using these samples, how would you obtain a $p$-val for testing if $\sigsq > 1.364$?}\spc{5}

\hardsubproblem{[MA] Using these samples, how would you estimate $\corr{\theta~|~X}{~\sigsq~|~X}$ i.e. the correlation between the posterior distributions of the two parameters?}\spc{3}

%\easysubproblem{If $\Xoneton~|~\theta, \sigsq \iid \normnot{\theta}{\sigsq}$ and $\theta \sim \normnot{\mu_0}{\tausq}$ write the distribution of $\theta~|~X,\sigsq$. Hint: it's in the notes and it was HW6 6(d). Note this problem is independent of the other problems.}\spc{5}

\easysubproblem{Find $\cprob{\theta}{X,~\sigsq}$ by using the full posterior kernel from (a) and then conditioning on $\sigsq$. You should get the same answer as we did before the midterm.}\spc{3}

\easysubproblem{Find $\cprob{\sigsq}{X,~\theta}$ by using the full posterior kernel from (a)  and then conditioning on $\theta$. You should get the same answer as we did before the midterm.}\spc{4}

%\intermediatesubproblem{Show that $\cprob{\sigsq}{X}$ is an inverse gamma distribution and find its parameters.}\spc{4}

\hardsubproblem{Show that $\cprob{\theta}{X}$ is a non-standard $T$ distribution and find its parameters. Assume the prior $\prob{\theta,~\sigsq} \propto \oneover{\sigsq}$. The answer is in the notes, but try to do it yourself.}\spc{15}


\hardsubproblem{Show that $\cprob{\sigsq}{X}$ is an inverse gamma and find its parameters. Assume the prior $\prob{\theta,~\sigsq} \propto \oneover{\sigsq}$. The answer is in the notes, but try to do it yourself.}\spc{12}


%\intermediatesubproblem{How does this compare to 2(j)? Note that $X \sim \invgammanot{\alpha}{\beta}$ then $cX \sim \invgammanot{\alpha}{\frac{\beta}{c}}$.}\spc{2}

\easysubproblem{Write down the distribution of $\cprob{X^*}{X}$ assuming the prior $\prob{\theta,~\sigsq} \propto \oneover{\sigsq}$. This is in the notes.}\spc{1}

\extracreditsubproblem{Prove what you wrote in the previous question: $\cprob{X^*}{X}$ is the non-standard $T$ distribution and find its parameters.}\spc{0}


\intermediatesubproblem{Explain how to sample from the distribution of $\cprob{X^*}{X}$. Also in the notes.}\spc{9}

\intermediatesubproblem{Now consider the informative conjugate prior of $\prob{\theta,~\sigsq} = \cprob{\theta}{\sigsq} \prob{\sigsq}$ where $\cprob{\theta}{\sigsq} = \normnot{\mu_0}{\frac{\sigsq}{m}}$ and $\prob{\sigsq} = \invgammanot{\overtwo{n_0}}{\overtwo{n_0 \sigsq_0}}$ i.e. the general normal-inverse-gamma. What is its kernel? Collect common terms and be neat.}\spc{9}


\hardsubproblem{[MA] If $\Xoneton~|~\theta, \sigsq \iid \normnot{\theta}{\sigsq}$ and given the general prior above, find the posterior and demonstrate it that the normal-inverse gamma is conjugate for the normal likelihood with both mean and variance unknown. This is what I did \emph{not} do in class.}\spc{13}

\end{enumerate}

\problem{We model the returns of S\&P 500 here.}

\begin{enumerate}
\easysubproblem{Below are the 16,428 daily returns (as a percentage) of the S\&P 500 dating back to January 4, 1950 and the code used to generate it. Does the data look normal? Yes/no}\spc{0}

\begin{figure}[h]
\centering
\includegraphics[width=7in]{daily_returns}
\end{figure}

%\begin{verbatim}
%X = read.csv('sp_tot_ret_price_1950.csv')
%n = nrow(X)
%n
%hist(X[,4], br = 1000, 
%  main = 'daily returns (as a percentage) of the S&P 500')
%\end{verbatim}

\intermediatesubproblem{Do you think the data is $\iid$? Explain.}\spc{1}

\intermediatesubproblem{Assume $\iid$ normal data regardless of what you wrote in (a) and (b). The sample average is $\xbar = 0.0003415$ and the sample standard deviation is $s = 0.0096$. Under an objective prior, give a 95\% credible region for the true mean daily return.}\spc{4}

\hardsubproblem{Give a 95\% credible region for \emph{tomorrow's} return using functions in Table~\ref{tab:eqs}.}\spc{4}

\end{enumerate}


\end{document}



\problem{This problem is about the normal-normal model using a \qu{semi-conjugate} prior. Assume $\Xoneton~|~\theta, \sigsq \iid \normnot{\theta}{\sigsq}$ throughout.}

\begin{enumerate}

\easysubproblem{If $\theta$ and $\sigsq$ are assumed to be independent, how can $\prob{\theta,~\sigsq}$ be factored?}\spc{1}

\easysubproblem{If $\prob{\theta} = \normnot{\mu_0}{\tausq}$ and $\prob{\sigsq} \sim \invgammanot{\overtwo{n_0}}{\overtwo{n_0 \sigsq_0}}$, find the kernel of the joint posterior, $\cprob{\theta,~\sigsq}{X}$}.\spc{4}

\hardsubproblem{Show that this kernel can be factored into the kernel of a normal where the leftover is \textit{not} the kernel of an inverse gamma. This is in the lecture notes.}\spc{12}

\hardsubproblem{[MA] Find the posterior mode of $\sigsq$ using $k(\sigsq~|~X)$.}\spc{5}

\hardsubproblem{Describe how you would sample from $k(\sigsq~|~X)$. Make all steps explicit and use the notation from Table~\ref{tab:eqs}.}\spc{10}

\hardsubproblem{Describe how you would sample from $\cprob{\theta,~\sigsq}{X}$. Make use of the sampling algorithm in the previous question. Make all steps explicit and use the notation from Table~\ref{tab:eqs}.}\spc{10}
 


\hardsubproblem{What are the two main disadvantages of grid sampling?}\spc{4}

\hardsubproblem{Why do you think the prior $\prob{\theta} = \normnot{\mu_0}{\tausq}$ and $\prob{\sigsq} \sim \invgammanot{\overtwo{n_0}}{\overtwo{n_0 \sigsq_0}}$ is called \qu{semi-conjugate}?}\spc{4}


\extracreditsubproblem{[MA] Find the MMSE of $\sigsq$}\spc{0}

\end{enumerate}



\end{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\problem{These are questions about McGrayne's book, chapter 17 and the Epilogue.}

\begin{enumerate}

\easysubproblem{What do the computer scientists who adopted Bayesian methods care most about and whose view do they subscribe to? (p233)}\spc{1}

\easysubproblem{How was \qu{Stanley} able to cross the Nevada desert?}\spc{3}

\easysubproblem{What two factors are leading to the \qu{crumbling of the Tower of Babel?}}\spc{3}

\intermediatesubproblem{Does the brain work through iterative Bayesian modeling?}\spc{4}

\easysubproblem{According to Geman, what is the most powerful argument for Bayesian Statistics?}\spc{3}

\end{enumerate}







